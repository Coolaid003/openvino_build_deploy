{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0a465fbf",
   "metadata": {},
   "source": [
    "# Latent Consistency Model using torch.compile with OpenVINO backend\n",
    "This notebook provides instructions how to run Latent Consistency Model (LCM). It allows to setup standard Hugging Face diffusers pipeline and Optimum Intel pipeline optimized for Intel hardware including CPU and GPU. Running inference on CPU and GPU it is easy to compare performance and time required to generate an image for provided prompt. The notebook can be also used on other Intel hardware with minimal or no modifications.  \n",
    "\n",
    "Optimum Intel is an interface from Hugging Face between both diffusers and transformers libraries and various tools provided by Intel to accelerate pipelines on Intel hardware. It allows to perform quantization of the models hosted on Hugging Face.\n",
    "In this notebook OpenVINO is used for AI-inference acceleration as a backend for Optimum Intel! \n",
    "\n",
    "For more details please refer to Optimum Intel repository\n",
    "https://github.com/huggingface/optimum-intel\n",
    "\n",
    "<img src=\"https://github.com/openvinotoolkit/openvino_notebooks/assets/105707993/a668529a-e1bd-46c6-9be4-1e6ca705c939\"/>\n",
    "\n",
    "\n",
    "LCMs are the next generation of generative models after Latent Diffusion Models (LDMs). They are proposed to overcome the slow iterative sampling process of Latent Diffusion Models (LDMs), enabling fast inference with minimal steps (from 2 to 4) on any pre-trained LDMs (e.g. Stable Diffusion). To read more about LCM please refer to https://latent-consistency-models.github.io/\n",
    "\n",
    "#### Table of contents:\n",
    "- [Prerequisites](#Prerequisites)\n",
    "- [Full precision model on the CPU](#Using-full-precision-model-in-CPU-with-LatentConsistencyModelPipeline)\n",
    "\n",
    "\n",
    "### Installation Instructions\n",
    "\n",
    "This is a self-contained example that relies solely on its own code.\n",
    "\n",
    "<img referrerpolicy=\"no-referrer-when-downgrade\" src=\"https://static.scarf.sh/a.png?x-pxid=5b5a4db0-7875-4bfb-bdbd-01698b5b1a77&file=notebooks/latent-consistency-models-image-generation/latent-consistency-models-optimum-demo.ipynb\" />\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "523a3f91",
   "metadata": {},
   "source": [
    "### Prerequisites\n",
    "[back to top ⬆️](#Table-of-contents:)\n",
    "\n",
    "Install required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec2a1a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -q \"openvino>=2023.3.0\"\n",
    "!{sys.executable} -m pip install -q \"accelerate\" \"diffusers\" \"ipywidgets\" \"torch>=2.1.1\" \"transformers>=4.33.0\" --extra-index-url https://download.pytorch.org/whl/cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b4af452",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from diffusers import StableDiffusionPipeline\n",
    "\n",
    "import openvino.frontend.pytorch.torchdynamo.backend\n",
    "\n",
    "import time\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6960adc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2857b2f8",
   "metadata": {},
   "source": [
    "### Using full precision model in CPU with `LatentConsistencyModelPipeline`\n",
    "[back to top ⬆️](#Table-of-contents:)\n",
    "\n",
    "Standard pipeline for the Latent Consistency Model(LCM) from Diffusers library is used here. For more information please refer to  https://huggingface.co/docs/diffusers/en/api/pipelines/latent_consistency_models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c23ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = torch.Generator(\"cpu\").manual_seed(1024)\n",
    "\n",
    " \n",
    "\n",
    "model_id = \"runwayml/stable-diffusion-v1-5\"\n",
    "\n",
    "pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float32)\n",
    "\n",
    " \n",
    "\n",
    "pipe.unet = torch.compile(pipe.unet, backend=\"openvino\", options={\"device\": \"GPU.0\"})\n",
    "\n",
    "pipe.vae.decode = torch.compile(pipe.vae.decode, backend=\"openvino\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a475fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"A cute squirrel in the forest, portrait, 8k\"\n",
    " \n",
    "start_time = time.time()\n",
    "\n",
    "image = pipe(prompt, num_inference_steps=50, generator=generator).images[0]\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"Time taken: \", end_time - start_time)   \n",
    "\n",
    "image"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "openvino_notebooks": {
   "imageUrl": "https://github.com/openvinotoolkit/openvino_notebooks/blob/latest/notebooks/stable-diffusion-v2/stable-diffusion-v2-optimum-demo.png?raw=true",
   "tags": {
    "categories": [
     "Model Demos",
     "AI Trends"
    ],
    "libraries": [],
    "other": [],
    "tasks": [
     "Text-to-Image"
    ]
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
